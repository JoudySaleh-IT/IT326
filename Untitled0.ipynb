{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvP3CLXh2dHMQmZxOHpLFf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoudySaleh-IT/IT326/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Correlation-based Feature Selection:**\n"
      ],
      "metadata": {
        "id": "tWu4_GlfVX38"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qP6qUNgDd7o",
        "outputId": "218b3c95-8e81-4d70-b71b-7c5a0305eea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: Index(['exang', 'oldpeak'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "selector = SelectKBest(score_func=f_classif, k=2)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "\n",
        "selected_features = X.columns[selector.get_support()]\n",
        "print(\"Selected Features:\", selected_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This research aims to determine which elements in a health dataset are most associated with predicting the probability of a heart attack. Improving the accuracy and interpretability of the model is essential for this purpose.\n",
        "\n",
        "• Defining Features and Target: The dataset is first divided into features (all columns except the final one) and the target variable (the last column, which represents the risk of a heart attack).\n",
        "\n",
        "• Feature Selection Process: The SelectKBest approach is applied using the ANOVA F-test (f_classif), which evaluates the features based on their statistical significance in relation to the target variable. In this case, we choose the top two features that have the highest impact on predicting heart attack risk.\n",
        "\n",
        "• Results: The selected features are exang (exercise-induced angina) and oldpeak (ST depression induced by exercise relative to rest). This suggests that these characteristics have the most influence on heart attack risk in the dataset."
      ],
      "metadata": {
        "id": "WfLujFQ6Q64M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Wrapper Methods**\n",
        "### **Recursive Feature Elimination:**"
      ],
      "metadata": {
        "id": "_7iLaoOAVER8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "rfe = RFE(model, n_features_to_select=2)\n",
        "X_new = rfe.fit_transform(X, y)\n",
        "\n",
        "\n",
        "selected_features = [i for i, mask in enumerate(rfe.support_) if mask]\n",
        "print(\"Selected Features:\", selected_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5udj_S_GZOQM",
        "outputId": "49202839-c01a-4c67-84fb-60e376e32f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: [1, 8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The red box is a description, not an error!\n",
        "\n",
        "This analysis aims to identify the most significant features in a health dataset for predicting heart attack risk, thereby improving the model’s accuracy and interpretability.\n",
        "\n",
        "- **Defining Features and Target:** The dataset is divided into independent features (all columns except the final one) and the target variable (the last column, which represents the risk of a heart attack).  \n",
        "- **Model Selection:** **Logistic Regression** is used as the base estimator for the **Recursive Feature Elimination (RFE)** method, which is commonly applied in binary classification tasks like predicting heart attack risk.  \n",
        "- **Recursive Feature Elimination Process:** The model is trained on the data, and the least important features are systematically removed until only the **top two features** remain.  \n",
        "\n",
        "### **Results:**\n",
        "The two most important selected features are:\n",
        "- **`sex` (Gender)**, which corresponds to **column index 1**.\n",
        "- **`thalach` (Maximum Heart Rate Achieved)**, which corresponds to **column index 8**.\n",
        "\n",
        "This indicates that these two features (`sex` and `thalach`) have the most significant influence on determining heart attack risk based on this analytical model."
      ],
      "metadata": {
        "id": "-FY_p_Y2UuOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Embedded Methods**\n",
        "### **L1 Regularization:**"
      ],
      "metadata": {
        "id": "5oO4EvHqZw2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the last column is the target\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "# Use L1 Regularization (LASSO) for feature selection\n",
        "model = Lasso(alpha=0.1)\n",
        "model.fit(X, y)\n",
        "\n",
        "\n",
        "# Display the selected features (features with non-zero coefficients)\n",
        "selected_features = X.columns[model.coef_ != 0]\n",
        "print(\"Selected Features:\", selected_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sise1s4EbEuA",
        "outputId": "56b31b06-2a2f-4f91-97c7-ebfa49ff8511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: Index(['cp', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This analysis aims to identify the most important features in a health dataset for predicting the risk of a heart attack, helping to improve model accuracy and reduce computational complexity.  \n",
        "\n",
        " **Model Setup:**  \n",
        "1. **Defining Features and Target:**  \n",
        "    The dataset is divided so that **X** represents all features (all columns except the last one), while **y** represents the target variable (occurrence of a heart attack).  \n",
        "\n",
        "2. **Applying Lasso:**  \n",
        "    The **Lasso (Least Absolute Shrinkage and Selection Operator) model** is used, which is a form of L1 regularization that reduces the impact of less important features by assigning their weights to zero.\n",
        "\n",
        "    The **regularization parameter (alpha = 0.1)** is set, which controls the amount of shrinkage applied to the coefficients.  \n",
        "\n",
        "\n",
        "\n",
        " **Feature Selection:**  \n",
        "\n",
        "After training the model on the dataset, the coefficients associated with each feature are examined. Features that retain non-zero coefficients are considered the most significant.  \n",
        "\n",
        " **Results:**  \n",
        "\n",
        "According to the Lasso analysis, the most influential features for predicting heart attack risk are:  \n",
        "**['cp', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']**  \n",
        "This indicates that these features play a key role in determining heart attack risk based on the available data."
      ],
      "metadata": {
        "id": "0t06-LcjY6z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save the dataset after preprocessing :**\n"
      ],
      "metadata": {
        "id": "0ZVfCVriaIK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"The_Processed_data.csv\")"
      ],
      "metadata": {
        "id": "5cQp6Jx7bZ3B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}